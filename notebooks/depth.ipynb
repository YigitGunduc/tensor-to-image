{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHaQkNvlc1ki",
    "outputId": "23afd6fb-521c-4b67-d765-22812a8a5bab"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_R2JVOec2PY",
    "outputId": "5ffe6ee9-550c-4453-961c-727307f38bf6"
   },
   "outputs": [],
   "source": [
    "!unzip /content/gdrive/MyDrive/indoor_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMZaGHOlc0SD",
    "outputId": "9f0ad718-d88a-4384-a315-fc8be1109a3e"
   },
   "outputs": [],
   "source": [
    "dataset_path = '../../../depth/dataset/test/LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Mx-LXgLc0SM"
   },
   "outputs": [],
   "source": [
    "input_paths = glob.glob(dataset_path + '/**/color/*.png')\n",
    "target_paths = glob.glob(dataset_path + '/**/depth_vi/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFbmIbP_c0SN",
    "outputId": "56e6ada1-e53b-4791-ec22-97c9b3045379"
   },
   "outputs": [],
   "source": [
    "print(target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OVZgPjtc0SP"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "EPOCHS = 100\n",
    "LAMBDA = 100\n",
    "BATCH_SIZE = 8\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "patch_size = 8\n",
    "num_patches = (IMG_HEIGHT // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "embed_dim = 64\n",
    "num_heads = 2 \n",
    "ff_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g89DtSq_c0SQ"
   },
   "outputs": [],
   "source": [
    "real = []\n",
    "targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvaXbs4lc0SR"
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "\n",
    "    image_path = path[:-12] + 'c.png'\n",
    "    image_path = image_path.replace(\"depth_vi\", \"color\")\n",
    "    depth_path = path[:-12] + 'depth_vi.png'\n",
    "\n",
    "\n",
    "    input_image = tf.io.read_file(image_path)\n",
    "    input_image = tf.image.decode_jpeg(input_image)\n",
    "    \n",
    "    target_image = tf.io.read_file(depth_path)\n",
    "    target_image = tf.image.decode_jpeg(target_image)\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    target_image = tf.cast(target_image, tf.float32)\n",
    "\n",
    "\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8_ilo0Fc0SS"
   },
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opCaZjvRc0ST"
   },
   "outputs": [],
   "source": [
    "def normalize(input_image, target_image):\n",
    "    input_image = input_image / 255\n",
    "    target_image = target_image / 255\n",
    "\n",
    "    return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvQKHD3-c0SU"
   },
   "outputs": [],
   "source": [
    "def load_image_train(depth_path):\n",
    "    input_image, target = load(depth_path)\n",
    "    input_image, target = resize(input_image, target,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, target = normalize(input_image, target)\n",
    "\n",
    "    return input_image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i48PBiP7c0SU"
   },
   "outputs": [],
   "source": [
    "real = []\n",
    "targets = []\n",
    "import numpy as np\n",
    "for i in range(len(target_paths)):\n",
    "    #inputs, target = load(target_paths[i])\n",
    "    inputs, target = load_image_train(target_paths[i])\n",
    "    #inputs, target =  normalize(inputs, target)\n",
    "    real.append(inputs)\n",
    "    targets.append(target)\n",
    "\n",
    "real = np.array(real)\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yfKd4i_c0SV"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "1VCfus5zc0SV",
    "outputId": "c21309a4-f950-47d8-c27d-3520328f70bf"
   },
   "outputs": [],
   "source": [
    "plt.imshow(real[23])\n",
    "print(real[12].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "vtOUxl5oc0SV",
    "outputId": "00f762f6-9e0f-46a7-d984-c3a1ec089b4f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(targets[23].reshape(256, 256))\n",
    "print(targets[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVWWuvVic0SW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm6uhABxc0SW"
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqAxP9ayc0SX"
   },
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"SAME\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_mdkF59c0SX"
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNDm9KXXc0SY"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPZFwD5PP4af"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcQVzKBDc0SZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def Generator():\n",
    "\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(encoded_patches)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(64, num_heads, ff_dim)(x)\n",
    "\n",
    "    x = layers.Reshape((8, 8, 1024))(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=512)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=256)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = residual_block(x, downsample=False, filters=64)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, (5, 5), strides=(4, 4), padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "\n",
    "    x = residual_block(x, downsample=False, filters=32)\n",
    "\n",
    "    x = layers.Conv2D(1, (3, 3), strides=(1, 1), padding='same', use_bias=False, activation='tanh')(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DBHxlKHvc0Sa",
    "outputId": "0b70c08f-2c2c-4d01-dd44-e340c0b088c0"
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51J3xxeZRLEO",
    "outputId": "e3794664-9dcc-4d21-e38a-b08c27bdff4f"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxG6_fP1c0Sa"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZn1NNgbc0Sb"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYCaFUoGc0Sb"
   },
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw8T5T3Ac0Sd"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Qhap2DDc0Sd"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl9RqSOHc0Se"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display_list = [test_input[0], np.array(tar[0]).reshape(256, 256), np.array(prediction[0]).reshape(256, 256)]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def generate_batch_images(model, test_input, tar):\n",
    "    for i in range(len(test_input)):\n",
    "        prediction = model(test_input, training=True)\n",
    "        plt.figure(figsize=(15, 15))\n",
    "\n",
    "        display_list = [test_input[i], tar[i], prediction[i]]\n",
    "        title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "        for i in range(3):\n",
    "            plt.subplot(1, 3, i+1)\n",
    "            plt.title(title[i])\n",
    "            # getting the pixel values between [0, 1] to plot it.\n",
    "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2M-Jbjvc0Se"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, target):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            gen_output = generator(input_image, training=True)\n",
    "            gen_total_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "        \n",
    "\n",
    "        generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                              generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                              generator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wOgyEJmc0Se"
   },
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        # Train\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            train_step(input_image, target)\n",
    "        print()\n",
    "\n",
    "        generator.save_weights(f'depth-gen-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Kq8t1kc0Se"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((real, targets))\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1SXMOPoc0Se",
    "outputId": "ee25b332-c08f-4ec4-eb15-1d59a4e896b2"
   },
   "outputs": [],
   "source": [
    "fit(train_dataset, 10000, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6H20taNNc0Sf"
   },
   "outputs": [],
   "source": [
    "generator.save_weights('gen-depth-weights.h5')\n",
    "discriminator.save_weights('dics-depth-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9mSLHL9Ac0Sf",
    "outputId": "44e8b2a6-eec6-4041-c7f9-87da233911ba"
   },
   "outputs": [],
   "source": [
    "for example_input, example_target in train_dataset.take(54):\n",
    "    generate_images(generator, example_input, example_target)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image2image_depth-res.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
